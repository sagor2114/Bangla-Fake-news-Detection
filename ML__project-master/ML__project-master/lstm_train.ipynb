{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0jJMvu7vqxwZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dimension):\n",
        "        super(Attention, self).__init__()\n",
        "\n",
        "        self.u = nn.Linear(dimension, dimension)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.softmax = nn.Softmax(1)\n",
        "\n",
        "    def forward(self, h):\n",
        "        # h : Batch * timestep * dimension\n",
        "        #         print('h', h.shape)\n",
        "        x = self.u(h)\n",
        "        # u(h) : Batch * timestep * att_dim\n",
        "        # print('u(h)', x)\n",
        "\n",
        "        # tan(x) : Batch * timestep * att_dim\n",
        "        x = self.tanh(x)\n",
        "        # print('tanh(x)', x)\n",
        "\n",
        "        # softmax(x) : Batch * timestep * att_dim\n",
        "        x = self.softmax(x)\n",
        "        # print(x)\n",
        "        # print('softmax(h)', x.shape,  h.shape)\n",
        "        # Batch matrix multiplication\n",
        "        output = x * h\n",
        "        #         print('output ', output.shape)\n",
        "        output = torch.sum(output, dim=1)\n",
        "        #         print('output ', output.shape)\n",
        "        return output\n",
        "\n"
      ],
      "metadata": {
        "id": "Eoxl8oAHrIyp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionModel(torch.nn.Module):\n",
        "    def __init__(self, batch_size, output_size, hidden_size, vocab_size, embedding_length, embedding_matrix):\n",
        "        super(AttentionModel, self).__init__()\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.output_size = output_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_length = embedding_length\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_length)\n",
        "        et = torch.tensor(embedding_matrix, dtype=torch.float32)\n",
        "        self.word_embeddings.weights = nn.Parameter(et, requires_grad=False)\n",
        "        self.lstm = nn.LSTM(embedding_length, hidden_size=hidden_size, batch_first=True,\n",
        "                            dropout=0.5, num_layers=2, bidirectional=True)\n",
        "        self.label = nn.Linear(hidden_size * 2, output_size)\n",
        "        self.attn_module = Attention(hidden_size * 2)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input_sentences, batch_size=None):\n",
        "\n",
        "        input = self.word_embeddings(input_sentences)\n",
        "        output, (final_hidden_state, final_cell_state) = self.lstm(input)  \n",
        "        attn_output = self.attn_module(output)\n",
        "        logits = self.label(attn_output)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "YOA1NgpKrj3v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "import os.path\n"
      ],
      "metadata": {
        "id": "IJwjqIAGrtHf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getResult(y_test, y_pred):\n",
        "\n",
        "    if torch.is_tensor(y_test) and torch.is_tensor(y_pred):\n",
        "        y_test, y_pred = cudaTocpu(y_test, y_pred)\n",
        "    \n",
        "    report = metrics.classification_report(y_test, y_pred, output_dict=True)\n",
        "    true = report['1']\n",
        "    fake = report['0']\n",
        "\n",
        "    overall = {\"Accuracy\": metrics.accuracy_score(y_test, y_pred), \"recall\": metrics.recall_score(y_test, y_pred),\n",
        "               \"f1-score\": metrics.f1_score(y_test, y_pred), \"precision\": metrics.precision_score(y_test, y_pred) }\n",
        "\n",
        "    return true, fake, overall\n",
        "\n"
      ],
      "metadata": {
        "id": "rK04icLlr6KP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def printResult(experiment, overall, fake):\n",
        "    experiment = experiment.ljust(14)\n",
        "    res = \"{}     {:.2f}         {:.2f}        {:.2f}      #  {:.2f}         {:.2f}         {:.2f}\".format(experiment,overall['precision'],overall['recall'],overall['f1-score'],fake['precision'],fake['recall'],fake['f1-score'])\n",
        "    return res\n"
      ],
      "metadata": {
        "id": "4fgFwlOHr9f3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getReport(y_test,y_pred):\n",
        "\n",
        "    if torch.is_tensor(y_test) and torch.is_tensor(y_pred):\n",
        "        y_test, y_pred = cudaTocpu(y_test, y_pred)\n",
        "    print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
        "    print(\"Precision:\", metrics.precision_score(y_test, y_pred))\n",
        "    print(\"Recall:\", metrics.recall_score(y_test, y_pred))\n",
        "    print(\"F1-Score:\", metrics.f1_score(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\", metrics.confusion_matrix(y_test, y_pred))\n",
        "    print(metrics.classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "r0WtUO_usRXX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def saveResults(path,res):\n",
        "    if os.path.isdir('./results') == False:\n",
        "        os.mkdir('results')\n",
        "    path = 'results/'+path\n",
        "    if os.path.exists('./'+path)==False:\n",
        "        with open(path, 'w', encoding=\"utf8\") as file:\n",
        "            file.write(\"                                Overall               #               Fake                \\n\")\n",
        "            file.write(\"                   precision    recall      f1-score  #  precision    recall      f1-score\\n\")\n",
        "            file.write(res+\"\\n\")\n",
        "    else:\n",
        "        with open(path, 'a', encoding=\"utf8\") as file:\n",
        "            file.write(res+\"\\n\")\n"
      ],
      "metadata": {
        "id": "UUUeloxOsUvv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cudaTocpu(y_test,y_pred):\n",
        "    y_test = [ y.cpu() if y.is_cuda else y for y in y_test ]\n",
        "    y_pred = [ y.cpu() if y.is_cuda else y for y in y_pred ]\n",
        "\n",
        "    return y_test, y_pred"
      ],
      "metadata": {
        "id": "l_geXnEzsXaH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "learning_rater = 2e-5\n",
        "batch_size = 32\n",
        "output_size = 2\n",
        "hidden_size = 256\n",
        "embedding_length = 300\n",
        "epochs = 3\n",
        "\n",
        "in_channels = 1\n",
        "out_channels = 256\n",
        "kernel_heights = [1, 2, 3, 4]\n",
        "stride = 1\n",
        "padding = 0\n",
        "keep_probab = 0.8"
      ],
      "metadata": {
        "id": "qz15KkessZ6n"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_300 = '/content/drive/MyDrive/cc.bn.300.vec'"
      ],
      "metadata": {
        "id": "zIFfW9Lpsife"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/MyDrive/TrainTest_puncremove (1).csv\""
      ],
      "metadata": {
        "id": "hQqTYyqrs6-H"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "from keras_preprocessing import sequence,text\n",
        "\n",
        "import string, re\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "metadata": {
        "id": "iUPkYE6FtFV2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(test_sen=None):\n",
        "\n",
        "\n",
        "    EMBEDDING_FILE = EMBEDDING_300\n",
        "\n",
        "    df = pd.read_csv(DATA_PATH)\n",
        "    X = df[\"content\"].values\n",
        "    Y = df[\"label\"].values\n",
        "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=109)\n",
        "\n",
        "    # data preprocessing\n",
        "    print(X[0])\n",
        "    puncList = [\"।\", \"”\", \"“\", \"’\"]\n",
        "    x = \"\".join(puncList)\n",
        "    filterString = x + '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n০১২৩৪৫৬৭৮৯'\n",
        "    tokenizer = text.Tokenizer(num_words=50000, filters=filterString, lower=False,)\n",
        "    tokenizer.fit_on_texts(x_train)\n",
        "    train_idx = tokenizer.texts_to_sequences(x_train)\n",
        "    test_idx = tokenizer.texts_to_sequences(x_test)\n",
        "    word_index = tokenizer.word_index\n",
        "\n",
        "    embeddings_index = {}\n",
        "    for i, line in enumerate(open(EMBEDDING_FILE, encoding=\"utf-8\")):\n",
        "        val = line.split()\n",
        "        embeddings_index[val[0]] = np.asarray(val[1:], dtype='float32')\n",
        "    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
        "    for word, i in word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "\n",
        "    x_train = sequence.pad_sequences(train_idx, maxlen=32, padding='post', truncating='post')\n",
        "    x_test = sequence.pad_sequences(test_idx, maxlen=32, padding='post', truncating='post')\n",
        "\n",
        "    test_size = len(x_test)\n",
        "\n",
        "    dev_size = (int)(test_size * 0.1)\n",
        "\n",
        "    x_dev = x_test[:dev_size]\n",
        "    x_test = x_test[dev_size:]\n",
        "    y_dev = y_test[:dev_size]\n",
        "    y_test = y_test[dev_size:]\n",
        "\n",
        "    x_train = torch.tensor(x_train, dtype=torch.long)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "\n",
        "    train = TensorDataset(x_train, y_train)\n",
        "    train_iter = DataLoader(train, batch_size=32)\n",
        "\n",
        "    x_test = torch.tensor(x_test, dtype=torch.long)\n",
        "    y_test = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "    test = TensorDataset(x_test, y_test)\n",
        "    test_iter = DataLoader(test, batch_size=32)\n",
        "\n",
        "    x_dev = torch.tensor(x_dev, dtype=torch.long)\n",
        "    y_dev = torch.tensor(y_dev, dtype=torch.float32)\n",
        "\n",
        "    valid = TensorDataset(x_dev, y_dev)\n",
        "    valid_iter = DataLoader(valid, batch_size=32)\n",
        "    word_embeddings = embedding_matrix\n",
        "    vocab_size = 50000\n",
        "\n",
        "\n",
        "    return vocab_size, word_embeddings, train_iter, valid_iter, test_iter"
      ],
      "metadata": {
        "id": "xFJ4dQ3rtZEu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "from sklearn import metrics\n",
        "import argparse"
      ],
      "metadata": {
        "id": "cABxzT9Atnqw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_history = []\n",
        "early_stop_monitor_vals = []\n",
        "best_score = 0"
      ],
      "metadata": {
        "id": "op50_63Htw0H"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clip_gradient(model, clip_value):\n",
        "    params = list(filter(lambda p: p.grad is not None, model.parameters()))\n",
        "    for p in params:\n",
        "        p.grad.data.clamp_(-clip_value, clip_value)\n"
      ],
      "metadata": {
        "id": "F9O5GTLduBoo"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_iter, epoch, loss_fn):\n",
        "    total_epoch_loss = 0\n",
        "    total_epoch_acc = 0\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda()\n",
        "    optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "    steps = 0\n",
        "    model.train()\n",
        "    for idx, batch in enumerate(train_iter):\n",
        "        text, target = batch\n",
        "        target = torch.autograd.Variable(target).long()\n",
        "        if torch.cuda.is_available():\n",
        "            text = text.cuda()\n",
        "            target = target.cuda()\n",
        "        if (text.size()[0] is not 32):# One of the batch returned by BucketIterator has length different than 32.\n",
        "            continue\n",
        "        optim.zero_grad()\n",
        "        prediction = model(text)\n",
        "        loss = loss_fn(prediction, target)\n",
        "        num_corrects = (torch.max(prediction, 1)[1].view(target.size()).data == target.data).float().sum()\n",
        "        acc = 100.0 * (num_corrects/len(target))\n",
        "        loss.backward()\n",
        "        clip_gradient(model, 1e-1)\n",
        "        optim.step()\n",
        "        steps += 1\n",
        "        \n",
        "        if steps % 100 == 0:\n",
        "            print (f'Epoch: {epoch+1}, Idx: {idx+1}, Training Loss: {loss.item():.4f}, Training Accuracy: {acc.item(): .2f}%')\n",
        "        \n",
        "        total_epoch_loss += loss.item()\n",
        "        total_epoch_acc += acc.item()\n",
        "        \n",
        "    return total_epoch_loss/len(train_iter), total_epoch_acc/len(train_iter)\n"
      ],
      "metadata": {
        "id": "wWrG_AE4uE6v"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, val_iter, loss_fn):\n",
        "    total_epoch_loss = 0\n",
        "    total_epoch_acc = 0\n",
        "    model.eval()\n",
        "    y_pred = []\n",
        "    y_test = []\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(val_iter):\n",
        "            text, target = batch\n",
        "            if (text.size()[0] is not 32):\n",
        "                continue\n",
        "            # target = batch.label\n",
        "            target = torch.autograd.Variable(target).long()\n",
        "            if torch.cuda.is_available():\n",
        "                text = text.cuda()\n",
        "                target = target.cuda()\n",
        "            prediction = model(text)\n",
        "            loss = loss_fn(prediction, target)\n",
        "\n",
        "            y_test.extend(target.data)\n",
        "            y_pred.extend(torch.max(prediction, 1)[1].view(target.size()).data)\n",
        "            num_corrects = (torch.max(prediction, 1)[1].view(target.size()).data == target.data).sum()\n",
        "            acc = 100.0 * num_corrects/len(target)\n",
        "            total_epoch_loss += loss.item()\n",
        "            total_epoch_acc += acc.item()\n",
        "\n",
        "    return total_epoch_loss/len(val_iter), total_epoch_acc/len(val_iter), y_test, y_pred\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zVbElQ_duKQn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def checkpoint_model(model_to_save, path_to_save, current_score, epoch, model_name, mode='max'):\n",
        "    \"\"\"\n",
        "    Checkpoints models state after each epoch.\n",
        "    :param model_to_save:\n",
        "    :param optimizer_to_save:\n",
        "    :param path_to_save:\n",
        "    :param current_score:\n",
        "    :param epoch:\n",
        "    :param n_epoch:\n",
        "    :param mode:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    model_state = {'epoch': epoch + 1,\n",
        "                   'model_state': model_to_save.state_dict(),\n",
        "                   'score': current_score,\n",
        "                   }\n",
        "\n",
        "    # Save the model as a regular checkpoint\n",
        "    # torch.save(model_state, path_to_save + 'last.pth'.format(epoch))\n",
        "\n",
        "    checkpoint_history.append(current_score)\n",
        "    is_best = False\n",
        "\n",
        "    # If the model is best so far according to the score, save as the best model state\n",
        "    if ((np.max(checkpoint_history) == current_score and mode == 'max') or\n",
        "            (np.min(checkpoint_history) == current_score and mode == 'min')):\n",
        "        is_best = True\n",
        "        best_score = current_score\n",
        "        torch.save(model_state, path_to_save + '{}_best.pth'.format(model_name))\n",
        "\n",
        "    print('Current best', max(checkpoint_history), 'after epoch {}'.format(epoch))\n",
        "\n",
        "    return is_best\n",
        "\n"
      ],
      "metadata": {
        "id": "buZXYihEuNKW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_saved_model(model, path):\n",
        "    \"\"\"\n",
        "    Load a saved model from dump\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    checkpoint = torch.load(path)\n",
        "    model.load_state_dict(checkpoint['model_state'])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "j7_J6DVauQoH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_model(model_name):\n",
        "\n",
        "    \n",
        "    vocab_size, word_embeddings, train_iter, valid_iter, test_iter = load_dataset()\n",
        "    learning_rate = learning_rater\n",
        "    batch_size = 32\n",
        "    output_size = 2\n",
        "    hidden_size = 256\n",
        "    embedding_length = 300\n",
        "    epochs = 3\n",
        "\n",
        "    # in_channels = in_channels\n",
        "    # out_channels = out_channels\n",
        "    # kernel_heights = kernel_heights\n",
        "    # stride = stride\n",
        "    # padding = padding\n",
        "    # keep_probab = keep_probab\n",
        "\n",
        "\n",
        "    if model_name == 'CNN':\n",
        "        model = CNN(batch_size, output_size, in_channels, out_channels, kernel_heights, stride, padding, keep_probab, vocab_size, embedding_length, word_embeddings)\n",
        "\n",
        "    elif model_name == 'LSTM':\n",
        "        model = AttentionModel(batch_size, output_size, hidden_size, vocab_size, embedding_length, word_embeddings)\n",
        "\n",
        "\n",
        "\n",
        "    loss_fn = F.cross_entropy\n",
        "    path = \"/content/drive/MyDrive/HandWritten/\"\n",
        "    for epoch in range(epochs):\n",
        "        train_loss, train_acc = train_model(model, train_iter, epoch, loss_fn)\n",
        "        val_loss, val_acc, y_test, y_pred = eval_model(model, valid_iter, loss_fn)\n",
        "        _, f, o = getResult(y_test, y_pred)\n",
        "        current_f1 = f['f1-score']\n",
        "        checkpoint_model(model, path, current_f1, epoch+1, model_name, 'max')\n",
        "        print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}%, Val. Loss: {val_loss:3f}, Val. Acc: {val_acc:.2f}%')\n",
        "\n",
        "    \n",
        "    load_saved_model(model, path + '{}_best.pth'.format(model_name))\n",
        "    test_loss, test_acc, y_test, y_pred = eval_model(model, test_iter, loss_fn)\n",
        "    print(f'Test Loss: {test_loss:.3f}, Test Acc: {test_acc:.2f}%')\n",
        "\n",
        "    print(\"                                Overall               #               Fake                \")\n",
        "    print(\"                   precision    recall      f1-score  #  precision    recall      f1-score\")\n",
        "    _, f, o = getResult(y_test, y_pred)\n",
        "    res = printResult(model_name,o,f)\n",
        "    print(res)\n",
        "    path = model_name+\"_results.txt\"\n",
        "    saveResults(path, res)\n",
        "\n"
      ],
      "metadata": {
        "id": "dGSoQN0PuTb_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm(args):\n",
        "    run_model('LSTM')"
      ],
      "metadata": {
        "id": "NKEtvZpVuWyv"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "parser = argparse.ArgumentParser(description='Argparse!')\n",
        "subparsers = parser.add_subparsers()\n",
        "\n",
        "\n",
        "\n",
        "parser_q = subparsers.add_parser('LSTM')\n",
        "parser_q.set_defaults(func=lstm)\n",
        "\n",
        "\n",
        "parser.add_argument(\"-g\",\"--gpu\", action=\"store_true\")\n",
        "args = parser.parse_args()\n",
        "gpu = args.gpu\n",
        "if not gpu:\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "\n",
        "args.func(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "_vw0JbUsu5uj",
        "outputId": "faf5e979-9711-4323-d311-910eecc577e2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] [-g] {LSTM} ...\n",
            "ipykernel_launcher.py: error: invalid choice: '/root/.local/share/jupyter/runtime/kernel-edec1152-3c3f-41ec-8f9e-51c1fbff2151.json' (choose from 'LSTM')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_model('LSTM')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd00VuSVu-Pe",
        "outputId": "1147fb2c-95b5-40cc-ee46-a6dbe2b7e058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ঢাকা আগামী ২৪ ঘণ্টায় গাইবান্ধা বগুড়া সিরাজগঞ্জ জামালপুর ও টাঙ্গাইলের বন্যা পরিস্থিতি উন্নতির সম্ভাবনা রয়েছে ব্রহ্মপুত্র ও গঙ্গার পানি কমে যাওয়া অব্যাহত থাকায় এই পূর্বাভাস দিয়েছে বাংলাদেশ পানি উন্নয়ন বোর্ডের বন্যা পূর্বাভাস ও সতর্কীকরণ কেন্দ্র পূর্বাভাসে জানানো হয় বৃহস্পতিবার ২০ সেপ্টেম্বর সকাল ৯টায় তিনটি নদীর পাঁচটি পয়েন্টে পানি বিপদসীমার ওপর দিয়ে প্রবাহিত হয় যমুনা নদীর ফুলছড়ি পয়েন্টে ৯ সেন্টিমিটার সারিয়াকান্দিতে ২১ সেন্টিমিটার ও বাহাদুরাবাদ পয়েন্টে পাঁচ সেন্টিমিটার ওপর দিয়ে পানি প্রবাহিত হতে দেখা যায় এছাড়া আত্রাই নদীর বাঘাবাড়ী পয়েন্টে ১৩ সেন্টিমিটার ও ধলেশ্বরী নদীর এলাশিন পয়েন্টে ৩৩ সেন্টিমিটার ওপর দিয়ে পানি প্রবাহিত হতে দেখা যায় এদিকে আপার মেঘনা অববাহিকার প্রধান নদীগুলোর পানি সমতল হ্রাস পাচ্ছে যা পরবর্তী ৪৮ ঘণ্টা অব্যাহত থাকবে বলে জানানো হয়েছে পদ্মা ও যমুনার পানিও স্থিতিশীল রয়েছে গত ২৪ ঘণ্টায় ভারতে বৃষ্টিপাতের কোনো রেকর্ড নেই বলেও পূর্বাভাস রিপোর্টে উল্লেখ করা হয়েছে\n",
            "Epoch: 1, Idx: 100, Training Loss: 0.2625, Training Accuracy:  90.62%\n",
            "Current best 0.7567567567567567 after epoch 1\n",
            "Epoch: 01, Train Loss: 0.304, Train Acc: 87.15%, Val. Loss: 0.191497, Val. Acc: 77.73%\n",
            "Epoch: 2, Idx: 100, Training Loss: 0.0552, Training Accuracy:  96.88%\n",
            "Current best 0.7567567567567567 after epoch 2\n",
            "Epoch: 02, Train Loss: 0.114, Train Acc: 95.36%, Val. Loss: 0.251435, Val. Acc: 77.34%\n",
            "Epoch: 3, Idx: 100, Training Loss: 0.0009, Training Accuracy:  100.00%\n",
            "Current best 0.7816091954022989 after epoch 3\n",
            "Epoch: 03, Train Loss: 0.051, Train Acc: 97.85%, Val. Loss: 0.271233, Val. Acc: 80.08%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O8-2q-0MvaaX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}